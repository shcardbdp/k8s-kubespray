FROM jupyter/all-spark-notebook

ARG VERSION
LABEL version=$VERSION device-type=gpu

USER root

COPY --from=nvidia/cuda:9.2-cudnn7-devel-ubuntu18.04 /usr/local/cuda-9.2/ /usr/local/cuda-9.2

RUN ln -s /usr/local/cuda-9.2 /usr/local/cuda &&\
	rm -rf /var/lib/apt/lists/*

USER $NB_UID  

ENV PATH "/usr/local/nvidia/bin:/usr/local/cuda/bin:$PATH"
ENV LD_LIBRARY_PATH "/usr/local/cuda/lib:/usr/local/cuda/lib64"
ENV LIBRARY_PATH "/usr/local/cuda/lib64/stubs:$LIBRARY_PATH"

ENV NVIDIA_VISIBLE_DEVICES all
ENV NVIDIA_DRIVER_CAPABILITIES all
ENV NVIDIA_REQUIRE_CUDA "cuda>=9.0"

# Configure environment
ENV LANG=C.UTF-8 LC_ALL=C.UTF-8
ENV CONDA_DIR /opt/conda 
ENV PATH $CONDA_DIR/bin:$PATH
ENV LD_LIBRARY_PATH /usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:$LD_LIBRARY_PATH

ADD fix-permissions /usr/local/bin/fix-permissions

USER root
# ==================================================================
# Unixodbc & clouder hive/impla odbc 
# ------------------------------------------------------------------
RUN  apt-get update && apt-get install -y wget vim openjdk-8-jdk unixodbc unixodbc-dev alien libaio1 libaio-dev && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*

COPY cloudera/ /data/
COPY oracle/ /data/
COPY odbcinst.ini /etc/odbcinst.ini
COPY odbc.ini /etc/odbc.ini


RUN apt-get install -y -f /data/clouderahiveodbc_2.5.25.1020-2_amd64.deb && \
    apt-get install -y -f /data/clouderaimpalaodbc_2.5.42.1031-2_amd64.deb && \
    rm -rf /opt/cloudera/hiveodbc/lib/64/cloudera.hiveodbc.ini && \
    rm -rf /opt/cloudera/hiveodbc/lib/64/cloudera.impalaodbc.ini && \
    cp /data/cloudera.*.ini /etc/ && \
    cp /data/HiveJDBC41.jar /data/ImpalaJDBC41.jar /usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext
    

# ==================================================================
#  JDBC CLI client
# ------------------------------------------------------------------
COPY connector/datalake.properties /etc/datalake/datalake.properties
COPY connector/JdbcClient.java /usr/local/bin/
COPY connector/jdbc-cli /usr/local/bin
ADD connector/dbi.py /opt/conda/lib/python3.6/site-packages/shcard/

RUN javac /usr/local/bin/JdbcClient.java && \
    chmod 755 /usr/local/bin/jdbc-cli && \
    chmod 777 /etc/datalake/datalake.properties 

# ==================================================================
# Oracle sqlplus & odbc extension
# ------------------------------------------------------------------
RUN alien -i /data/oracle-instantclient12.2-basic-12.2.0.1.0-1.x86_64.rpm && \
    alien -i /data/oracle-instantclient12.2-sqlplus-12.2.0.1.0-1.x86_64.rpm && \
    alien -i /data/oracle-instantclient12.2-devel-12.2.0.1.0-1.x86_64.rpm && \
    alien -i /data/oracle-instantclient12.2-odbc-12.2.0.1.0-2.x86_64.rpm && \
    alien -i /data/oracle-instantclient12.2-jdbc-12.2.0.1.0-1.x86_64.rpm && \
    cp /usr/lib/oracle/12.2/client64/lib/ojdbc8.jar /usr/lib/jvm/java-8-openjdk-amd64/jre/lib/ext

USER $NB_UID

ENV JAVA_HOME       /usr/lib/jvm/java-8-openjdk-amd64
ENV ORACLE_HOME     /usr/lib/oracle/12.2/client64
ENV PATH            $JAVA_HOME/bin:$ORACLE_HOME/bin:${PATH}
ENV LD_LIBRARY_PATH /usr/lib/x86_64-linux-gnu:${ORACLE_HOME}/lib:${LD_LIBRARY_PATH}
ENV LD_PRELOAD /usr/lib/x86_64-linux-gnu/libodbcinst.so

RUN conda install --yes --quiet  \
        thrift \
        thrift_sasl \
        && \
    conda clean -tipsy      

# request by Song :: equal to mllight lib
##################################################
RUN conda install --quiet --yes \
        tensorflow-gpu==1.12.0 \
        keras==2.2.4 \
        pytorch torchvision -c pytorch

RUN conda install --yes --quiet -c lukepfister pycuda==2017.1 scikits.cuda

RUN conda install --quiet --yes \
#         numpy==1.16.0 \ 1.16.1
#         pandas==0.23.4 \
        cx_oracle==7.0.0 \
        nltk==3.4 \
        # seaborn==0.9.0 \ 
#         bokeh==1.0.4 \ 0.13.0
#         matplotlib==3.0.2 \ 2.2.3
        pydotplus==2.0.2 \
#         networkx==2.2 \
        plotly==3.5.0 \
#         scikit-learn==0.20.2 \
        imbalanced-learn==0.4.3 \
#         statsmodels==0.9.0 \
#         scipy==1.1.0 \
        implicit==0.3.7 \
        lightfm==1.15 \
#         cython==0.29.3 \ 0.28.5
#         numba==0.42.0 \ 0.38.1 
#         beautifulsoup4==4.7.1 \ 4.6.3
        autopep8==1.4.3 \
        pytest==4.1.1 \
        pycrypto \
        hyperopt==0.1.2 \
    && conda clean -tipsy && \        
    rm -rf $CONDA_DIR/share/jupyter/lab/staging && \
    rm -rf /home/$NB_USER/.cache/yarn && \
    fix-permissions $CONDA_DIR && \
    fix-permissions /home/$NB_USER


RUN pip install --quiet --no-cache-dir \
        xgboost==0.81 \
        eli5==0.8.1 \ 
        mlxtend==0.15.0.0 \
        lightgbm==2.2.2 \
        catboost==0.12.2 \
        # plotnine==0.5.1 \ # plotnine 0.5.1 has requirement matplotlib>=3.0.0, but you'll have matplotlib 2.2.3 which is incompatible.
        missingno==0.4.1 \
        pyLDAvis==2.1.2 \
        pyodbc==4.0.25 \
        pyspark==2.3 \
        Edward \
        dfply \
        dplython

RUN pip install --quiet --no-cache-dir \
        surprise==0.1 \
#         tensorboard==1.12.2 \ 1.12.0
        tensorflowonspark==1.4.2 \
        tensorboard_logger==0.1.0 \
        tensorboard_pytorch==0.7.1 \
        tensorboardX==1.6 \
        ipython-memory-usage==1.1 \
        nbresuse==0.3.0 \   
        gensim==3.7.0 \
        fasttext==0.8.3 \
        konlpy==0.5.1 \
        pycm==1.8 \
        apyori==1.1.1 \
        cufflinks==0.14.6 \
    && \
    rm -rf /home/$NB_USER/.cache/yarn 

# ==================================================================
# Hive/impala, odbc connector
# ------------------------------------------------------------------
RUN conda install --yes --quiet  \
        thrift \
        thrift_sasl \
        impyla==0.14.1 \
        && \
    conda clean -tipsy && \
    rm -rf /home/$NB_USER/.cache/yarn && \
    fix-permissions $CONDA_DIR && \
    fix-permissions /home/$NB_USER

RUN pip install --quiet --no-cache-dir \
        thriftpy \
        pyodbc==4.0.25 \        
    && \
    rm -rf /home/$NB_USER/.cache/yarn 

RUN pip uninstall --yes pyzmq && pip  install --quiet --no-cache-dir pyzmq

# Cuz of zmq. Next time, Check the reason where pyzmq is installed  
RUN conda install --quiet --yes \
        jupyter_contrib_nbextensions==0.5.1 \
    && conda clean -tipsy && \        
    rm -rf $CONDA_DIR/share/jupyter/lab/staging && \
    rm -rf /home/$NB_USER/.cache/yarn && \
    fix-permissions $CONDA_DIR && \
    fix-permissions /home/$NB_USER

# ==================================================================
# spark setting
# ------------------------------------------------------------------
COPY spark/hosts /tmp/
COPY spark/conf.cloudera.yarn/ /opt/conf.cloudera.yarn/
COPY spark/hive/hive-site.xml /usr/local/spark/conf/
COPY spark/spark-defaults.conf /usr/local/spark/conf/
COPY spark/DbInterface.py /opt/conda/lib/python3.6/

# Setting env value
ENV HADOOP_CONF_DIR /opt/conf.cloudera.yarn
ENV YARN_CONF_DIR /opt/conf.cloudera.yarn


ENV SPARK_HOME /usr/local/spark
ENV PATH $SPARK_HOME/bin:${PATH}

ENV SPARK_CONF_DIR $SPARK_HOME/conf

ENV SPARK_YARN_USER_ENV='PYSPARK_PYTHON=/shcsw/anaconda3/bin/python'
ENV PYSPARK_DRIVER_PYTHON /opt/conda/bin/python
ENV PYSPARK_PYTHON /shcsw/anaconda3/bin/python

##################################################

USER root  

# Set up our notebook config.
RUN  TINI_VERSION=`curl https://github.com/krallin/tini/releases/latest | grep -o "/v.*\"" | sed 's:^..\(.*\).$:\1:'` && \
    curl -L "https://github.com/krallin/tini/releases/download/v${TINI_VERSION}/tini_${TINI_VERSION}.deb" > tini.deb && \
    dpkg -i tini.deb && \
    rm tini.deb && \
    apt-get clean
 

# ==================================================================
# jupyter setting
# ------------------------------------------------------------------
# Add gpu setting 
# RUN  ln -s /usr/local/cuda-9.0/lib64/libcurand.so.9.0 /usr/local/cuda-9.0/lib64/libcurand.so.8.0

COPY  jupyter/spark/jupyter_notebook_config.py /etc/jupyter/
COPY  notebooks/ /home/$NB_USER/notebooks/samples/
COPY  run_jupyter.sh /usr/local/bin/
RUN rm -rf /home/$NB_USER/work && rm -rf /home/$NB_USER/.rpmdb && chown -R $NB_USER:$NB_UID /home/$NB_USER/notebooks && \
    fix-permissions /etc/jupyter/ && fix-permissions /home/$NB_USER/notebooks/samples && \
    fix-permissions $CONDA_DIR && \
    fix-permissions /home/$NB_USER

# 1.0.9
# EXPOSE 32747 32748 32749 32750 32751 32752 32753 32754 32755 32756 32757 32758 32759 32760 32761 32762 32763 32764 32765 32766 32767

# 일반모델 DNN랩 (월) 1.0.10 Port 30820 30821
# EXPOSE 30820 30821

# 통합추천 랩(일) 1.0.11 Port 30822-30823
EXPOSE 30822 30823

# Add fonts for NHN fonts
COPY fonts/ /usr/share/fonts/

COPY entrypoint_spark.sh /usr/local/bin/
ENTRYPOINT [ "/usr/bin/tini", "--", "entrypoint_spark.sh"]
CMD [ "/usr/local/bin/run_jupyter.sh", "--no-browser", "--ip=0.0.0.0", "--allow-root", "--NotebookApp.token="]

USER $NB_UID
