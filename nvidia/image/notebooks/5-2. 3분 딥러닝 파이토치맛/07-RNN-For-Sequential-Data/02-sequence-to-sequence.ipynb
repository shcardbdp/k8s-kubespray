{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq 기계 번역\n",
    "\n",
    "2010년 이후 가장 큰 관심을 받은건 역시 알파고 였지만, 그와 더불어 크게 화제가 된 또다른 머신러닝 모델이 있었습니다.\n",
    "바로 한 언어를 다른 언어로 해석시켜주는 **뉴럴 기계번역(Neural Machine Translation)** 모델입니다. \n",
    "항상 RNN이 기계번역에 쓰였던 것은 아니지만, RNN 기반의 번역모델인 **Sequence to Sequence**(줄여서 Seq2Seq 이라고도 합니다) 모델은 기계번역의 새로운 패러다임을 열었다고 할 정도로 기존 번역모델의 성능을 아득히 뛰어넘었습니다.\n",
    "\n",
    "이름에서 알 수 있듯이 Seq2Seq 모델은 순차적인 형태의 배열 혹은 문장을 다른 문장으로 바꾸거나 번역해주는 모델입니다.\n",
    "일반적으로 Seq2Seq와 같은 기계번역 모델이 이러한 능력을 학습하려면 원문과 번역문이 쌍을 이루는 형태의 다량의 텍스트 데이터셋이 필요합니다.\n",
    "당연히 이런 데이터를 가지고 학습하는 모델들은 고용량 GPU와 복잡한 텍스트 전처리 과정, 그리고 긴 학습시간 등 꽤 많은 리소스를 필요로 합니다.\n",
    "\n",
    "그래서 이번 프로젝트에선 임의로 Seq2Seq 모델을 아주 간단화 시켰습니다.\n",
    "한 언어로 된 문장을 다른 언어로 된 문장으로 번역하는 덩치가 큰 모델이 아닌\n",
    "영어 알파벳 문자열(\"hello\")을 스페인어 알파벳 문자열(\"hola\")로 번역하는 Mini Seq2Seq 모델을 같이 구현해 보겠습니다.\n",
    "\n",
    "## Seq2Seq 개요\n",
    "\n",
    "지금까지 이 책을 읽으면서 이미 눈치를 채셨을 수도 있겠지만, 복잡한 일을 처리하는 딥러닝 모델이 단 하나의 신경망으로 이루어진 경우는 매우 드뭅니다.\n",
    "우리가 앞 프로젝트에서 같이 구현한 비교적 간단한 모델인 감정분석(Sentiment Analysis) 모델도 RNN 과 다층신경망, 이 두 신경망이 연결된 형태였습니다.\n",
    "이번 프로젝트의 메인 토픽인 Seq2Seq모델 또한 마찬가지입니다. 엄밀히 말하자면 Seq2Seq 모델은 서로 다른 역할을 하는 두개의 RNN을 이어붙인 신경망입니다\n",
    "\n",
    "두개의 RNN이 연결되어 있다는 점에서 Seq2Seq 모델이 매우 어렵고 복잡하게 느껴지실 수도 있습니다.\n",
    "하지만 실제 우리가 번역을 할때 거치는 생각과 과정을 곱씹어보면 Seq2Seq가 왜 이런 구조로 구현되었는지 쉽게 이해가 되실겁니다.\n",
    "일반적으로 우리가 영어와 같은 외국어를 한국어로 번역하는 과정은 다음과 같습니다.\n",
    "먼저 외국어 문장을 읽고 그 내용을 이해합니다.\n",
    "그다음 이러한 이해를 바탕으로 한국어 단어들을 하나 하나 문맥에 맞게 써내려갑니다.\n",
    "이처럼 번역은 원문의 이해와 번역문 작성, 이렇게 크게 두가지 동작을 필요로 합니다.  \n",
    "\n",
    "Seq2Seq 모델에선 이 두가지 동작을 **인코더(Encoder)** 와 **디코더(Decoder)** 라고 하는 각자 다른 RNN에 부여하므로써 기계번역을 실행합니다.\n",
    "첫번째 RNN인 **인코더(Encoder)** 는 원문을 입력받고 그 뜻을 학습합니다. 인코더를 통해 학습된 내용을 이어받는 **디코더(Decoder)** 는 원문의 내용을 바탕으로 번역문을 차례대로 출력합니다.\n",
    "\n",
    "### 인코더\n",
    "\n",
    "인코더는 원문의 내용을 학습하는 RNN 입니다.  \n",
    "한 마디로 원문 속의 모든 단어들을 입력받아 문장의 뜻을 내포하는 하나의 고정된 크기의 텐서로 압축시킵니다.\n",
    "이렇게 압축된 텐서는 원문의 뜻과 내용을 담고 있다고 하여 **Context Vector(내용 벡터)** 라고 부릅니다.\n",
    "\n",
    "### 디코더\n",
    "\n",
    "다시 말씀드리지만, 번역을 할 때에는 항상 '원문이 말하는 바가 무엇인가', 그리고 '번역문과 원문이 전하는 뜻이 같은가'라는 생각을 하고 있어야합니다.  \n",
    "이는 곧 번역문의 단어 하나, 글자 한 자를 작성할 때도 원문이 주는 정보에 입각하여야 한다는 뜻입니다.\n",
    "즉 디코더가 번역문의 단어나 토큰을 출력할 때 마다 인코더의 Context Vector를 어느 형태로든 전달받아야 합니다.\n",
    "\n",
    "![rl](./assets/encoder_decoder.png)\n",
    " \n",
    "사실 인코더의 Context Vector 를 디코더에 전해주는데는 여러 방법이 있습니다.\n",
    "원본 Sequence to Sequence 모델에선 인코더의 Context Vector 가 디코더에 입력되는 모든 번역문 토큰 벡터에 이어붙였습니다. 이렇게 구현함으로써 디코더가 다음 번역문 토큰을 예상할 때 원문의 내용을 고려할 수 있도록 말이죠.\n",
    "우리가 구현해 볼 Mini Seq2Seq은 이러한 동작은 생략하고 단순히 디코더 RNN 의 첫번쨰 Hidden State 을 인코더의 Context Vector 로 정의함으로써 원문의 내용을 디코더에 입력합니다.  \n",
    "Context Vector를 입력받은 디코더는 번역문 속의 토큰을 입력받아 번역문 속 다음 토큰을 예상합니다.\n",
    "디코더가 예상한 토큰과 실제 토큰을 비교하여 오차를 줄여나가는 것이 Seq2Seq 모델이 학습하는 기본원리입니다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seq2Seq 모델을 구현하고 기계번역을 해 봅시다.\n",
    "\n",
    "여느때와 마찬가지로 구현에 필요한 라이브러리들을 임포트합니다.\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번 프로젝트에선 워드 임베딩(Word Embedding)이 아닌 캐릭터 임베딩(Character Embedding)을 사용하겠습니다.\n",
    "즉 단어가 아닌 알파벳들을 벡터로 표현하여 알파벳의 배열인 단어를 벡터의 배열로 표현하겠습니다.\n",
    "\n",
    "앞의 프로젝트에서 했던것과 마찬가지로, 임베딩을 하기 위해선 '사전'을 정의해야 합니다. ascii 코드엔 총 256개의 캐릭터가 속해 있으므로, 모든 캐릭터를 사전에 담아내기 위해 vocab_size 를 ascii 코드의 총 갯수인 256으로 정의하겠습니다.\n",
    "\n",
    "```python\n",
    "vocab_size = 256  # ascii size\n",
    "```\n",
    "\n",
    "Seq2Seq 모델에 입력될 원문과 번역문 ascii 코드의 배열로 정의하고 파이토치 텐서로 바꿔줍니다.\n",
    "\n",
    "```python\n",
    "x_ = list(map(ord, \"hello\"))  # convert to list of ascii codes\n",
    "y_ = list(map(ord, \"hola\"))   # convert to list of ascii codes\n",
    "x = Variable(th.LongTensor(x_))\n",
    "y = Variable(th.LongTensor(y_))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seq2Seq 모델 클래스를 정의합니다.\n",
    "전 프로젝트와 마찬가지로 n_layer는 1로 정의해 주고 RNN 의 Hidden Size를 입력받도록 설정합니다.\n",
    "\n",
    "```python\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.n_layers = 1\n",
    "        self.hidden_size = hidden_size\n",
    "```\n",
    "\n",
    "임베딩 사이즈를 설정하고 인코더와 디코더를 LSTM 객체로 정의해줍니다.\n",
    "원래는 원문을 위한 임베딩과 번역문을 위한 임베딩을 따로 정의해 줘야 하지만 간단한 Seq2Seq 모델인 만큼 임베딩을 하나만 정의해 주겠습니다.\n",
    "\n",
    "```python\n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
    "        self.encoder = nn.LSTM(hidden_size, hidden_size)\n",
    "        self.decoder = nn.LSTM(hidden_size, hidden_size)\n",
    "```\n",
    "\n",
    "디코더가 번역문 속 다음 토큰을 예상하기 위해선 다음과 같이 작은 신경망을 하나 더 만들어 줘야합니다.\n",
    "\n",
    "```python\n",
    "        self.project = nn.Linear(hidden_size, vocab_size)\n",
    "```\n",
    "\n",
    "forward 함수를 구현하면서 위에 정의된 신경망 모듈과 객체들이 어떻게 서로 이어붙여 지는지 알아보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "인코더의 첫번째 Hidden State을 정의하고 인코더에 입력되는 원문인 'hello' 속의 모든 캐릭터를 임베딩시킵니다.\n",
    "\n",
    "```python\n",
    "def forward(self, inputs, targets):\n",
    "        initial_state = self._init_state()\n",
    "        embedding = self.embedding(inputs).unsqueeze(1)\n",
    "```     \n",
    "\n",
    "'hello'를 인코더에 입력시켜 encoder_state 이라는 텐서로 압축시킵니다.\n",
    "원문의 Context Vector인 encoder_state를 디코더의 첫번째 Hidden State 로 설정합니다.\n",
    "디코더가 번멱문 'hola'의 첫번째 토큰인 'h'를 예상하려면 null character 혹은 문장 시작 토큰(Start of Sentence Tocken)을 첫번째 입력데이터로써 받아야 합니다. 이번 예제에서는 ascii 번호 0을 문장 시작 토큰으로 설정하겠습니다.\n",
    "\n",
    "```python\n",
    "\n",
    "        encoder_output, encoder_state = self.encoder(embedding, initial_state)\n",
    "        decoder_state = encoder_state\n",
    "        decoder_input = Variable(th.LongTensor([[0]]))\n",
    "```\n",
    "\n",
    "디코더의 동작에 필요한 for loop 을 구현합니다.\n",
    "디코더는 인코더와는 달리 번역문 속의 토큰을 입력받을 때 마다 loss를 계산하는데 쓰일 결과값을 출력해야합니다.\n",
    "위에 정의한 decoder_input 과 encoder의 Context Vector인 decoder_state을 디코더에 입력합니다.\n",
    "\n",
    "```python\n",
    "        outputs = []\n",
    "        for i in range(targets.size()[0]): \n",
    "            decoder_input = self.embedding(decoder_input)\n",
    "            decoder_output, decoder_state = self.decoder(decoder_input, decoder_state)\n",
    "```\n",
    "\n",
    "decoder를 통해 나온 결과값은 다시 작은 신경망에 입력됩니다.\n",
    "이렇게 해서 원문의 내용과 현재의 번역문 토큰을 기반으로 추론해 본 번역문의 다음 토큰을 예상하는 결과값을 구합니다.\n",
    "이 결과값을 outputs라는 배열 속에 저장해 loss 를 계산할 때 사용하겠습니다.\n",
    "\n",
    "```python\n",
    "            # Project to the vocabulary size\n",
    "            projection = self.project(decoder_output.view(1, -1))  # batch x vocab_size\n",
    "            \n",
    "            # Make prediction\n",
    "            prediction = F.softmax(projection)  # batch x vocab_size\n",
    "            outputs.append(prediction)\n",
    "```\n",
    "\n",
    "마지막으로 디코더에 입력되는 데이터를 번역문의 토큰을 업데이트합니다.\n",
    "\n",
    "```python\n",
    "            # update decoder input\n",
    "            _, top_i = prediction.data.topk(1)  # 1 x 1\n",
    "            decoder_input = Variable(top_i)\n",
    "\n",
    "```\n",
    "\n",
    "번역문의 모든 토큰에 대한 결과값들을 배열이라 할 수 있는 outputs을 리턴합니다.\n",
    "\n",
    "```python\n",
    "        outputs = th.stack(outputs).squeeze()\n",
    "        return outputs\n",
    "```\n",
    "\n",
    "이렇게 모델의 구현이 끝났습니다.\n",
    "이제 vocab_size를 256으로, hidden_size를 16으로 설정해 모델을 생성하고 loss 함수와 optimizer를 정의합니다.\n",
    "\n",
    "```python\n",
    "seq2seq = Seq2Seq(vocab_size, 16)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = th.optim.Adam(seq2seq.parameters(), lr=1e-3)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1000번의 epoch에 걸쳐 모델을 학습시킵니다.\n",
    "\n",
    "```python\n",
    "log = []\n",
    "for i in range(1000):\n",
    "    prediction = seq2seq(x, y)\n",
    "    loss = criterion(prediction, y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss_val = loss.data[0]\n",
    "    log.append(loss_val)\n",
    "    if i % 100 == 0:\n",
    "        print(\"%d loss: %s\" % (i, loss_val))\n",
    "        _, top1 = prediction.data.topk(1, 1)\n",
    "        for c in top1.squeeze().numpy().tolist():\n",
    "            print(chr(c), end=\" \")\n",
    "        print()\n",
    "```\n",
    "\n",
    "matplotlib 라이브러리를 이용해서 loss 가 줄어드는 것을 한 눈에 확인하실 수 있습니다.\n",
    "\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(log)\n",
    "plt.ylabel('cross entropy loss')\n",
    "plt.show()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전체 코드\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello ->  [104, 101, 108, 108, 111]\n",
      "hola  ->  [104, 111, 108, 97]\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 256  # ascii size\n",
    "x_ = list(map(ord, \"hello\"))  # convert to list of ascii codes\n",
    "y_ = list(map(ord, \"hola\"))   # convert to list of ascii codes\n",
    "print(\"hello -> \", x_)\n",
    "print(\"hola  -> \", y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Variable(th.LongTensor(x_))\n",
    "y = Variable(th.LongTensor(y_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 104,  101,  108,  108,  111])\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f7f6040c7502>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mSeq2Seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSeq2Seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.n_layers = 1\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
    "        self.encoder = nn.LSTM(hidden_size, hidden_size)\n",
    "        self.decoder = nn.LSTM(hidden_size, hidden_size)\n",
    "        self.project = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        # Encoder inputs and states\n",
    "        initial_state = self._init_state()\n",
    "        embedding = self.embedding(inputs).unsqueeze(1)\n",
    "        # embedding = [seq_len, batch_size, embedding_size]\n",
    "        \n",
    "        # Encoder\n",
    "        encoder_output, encoder_state = self.encoder(embedding, initial_state)\n",
    "        # encoder_output = [seq_len, batch_size, hidden_size]\n",
    "        # encoder_state  = [n_layers, seq_len, hidden_size]\n",
    "\n",
    "        # Decoder inputs and states\n",
    "        decoder_state = encoder_state\n",
    "        decoder_input = Variable(th.LongTensor([[0]]))\n",
    "        \n",
    "        # Decoder\n",
    "        outputs = []\n",
    "        for i in range(targets.size()[0]): \n",
    "            decoder_input = self.embedding(decoder_input)\n",
    "            decoder_output, decoder_state = self.decoder(decoder_input, decoder_state)\n",
    "            \n",
    "            # Project to the vocabulary size\n",
    "            projection = self.project(decoder_output.view(1, -1))  # batch x vocab_size\n",
    "            \n",
    "            # Make prediction\n",
    "            prediction = F.softmax(projection)  # batch x vocab_size\n",
    "            outputs.append(prediction)\n",
    "            \n",
    "            # update decoder input\n",
    "            _, top_i = prediction.data.topk(1)  # 1 x 1\n",
    "            decoder_input = Variable(top_i)\n",
    "\n",
    "        outputs = th.stack(outputs).squeeze()\n",
    "        return outputs\n",
    "    \n",
    "    def _init_state(self, batch_size=1):\n",
    "        weight = next(self.parameters()).data\n",
    "        return (\n",
    "            Variable(weight.new(self.n_layers, batch_size, self.hidden_size).zero_()),\n",
    "            Variable(weight.new(self.n_layers, batch_size, self.hidden_size).zero_())\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq2Seq(\n",
      "  (embedding): Embedding(256, 16)\n",
      "  (encoder): LSTM(16, 16)\n",
      "  (decoder): LSTM(16, 16)\n",
      "  (project): Linear(in_features=16, out_features=256, bias=True)\n",
      ")\n",
      "tensor(1.00000e-03 *\n",
      "       [[ 2.9970,  2.8114,  4.2799,  ...,  3.7746,  3.7840,  5.4948],\n",
      "        [ 2.9797,  3.4032,  4.1419,  ...,  3.1983,  3.9454,  5.4524],\n",
      "        [ 2.9936,  3.4686,  4.0216,  ...,  3.4292,  4.0596,  4.8199],\n",
      "        [ 3.2152,  3.3866,  3.9634,  ...,  3.1042,  4.0616,  5.8624]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sangjunyum/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:36: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "seq2seq = Seq2Seq(vocab_size, 16)\n",
    "print(seq2seq)\n",
    "pred = seq2seq(x, y)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = th.optim.Adam(seq2seq.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context Vector torch.Size([1, 1, 16])\n",
      "0 loss: tensor(5.5453)\n",
      "",
      " ª 5 ^ \n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sangjunyum/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:30: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/Users/sangjunyum/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:8: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "100 loss: tensor(5.3443)\n",
      "h l l l \n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "200 loss: tensor(4.9505)\n",
      "h o l a \n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "300 loss: tensor(4.7128)\n",
      "h o l a \n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "400 loss: tensor(4.6448)\n",
      "h o l a \n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "500 loss: tensor(4.6143)\n",
      "h o l a \n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "600 loss: tensor(4.5861)\n",
      "h o l a \n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "700 loss: tensor(4.5741)\n",
      "h o l a \n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n",
      "Context Vector torch.Size([1, 1, 16])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-87dff9e6d41c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mloss_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sangjunyum/anaconda/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sangjunyum/anaconda/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     87\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     88\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "log = []\n",
    "for i in range(1000):\n",
    "    prediction = seq2seq(x, y)\n",
    "    loss = criterion(prediction, y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss_val = loss.data[0]\n",
    "    log.append(loss_val)\n",
    "    if i % 100 == 0:\n",
    "        print(\"%d loss: %s\" % (i, loss_val))\n",
    "        _, top1 = prediction.data.topk(1, 1)\n",
    "        for c in top1.squeeze().numpy().tolist():\n",
    "            print(chr(c), end=\" \")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAD8CAYAAACYebj1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff40155fb70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(log)\n",
    "plt.ylabel('cross entropy loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
