# 순차적인 데이터를 처리하는 RNN

RNN을 활용하여 영화 리뷰 감정 분석과 기계번역을 해봅니다.

  * [개념] RNN 기초
  * [프로젝트 1] 영화 리뷰 감정 분석
  * [프로젝트 2] Seq2Seq 기계 번역
  * 더 보기

## RNN 기초

우리가 지금까지 만든 딥러닝 모델들은 입력받은 데이터를 분류 하는 정도에 그쳤습니다.
물론 인공신경망을 통한 분류 작업은 컴퓨터과학에선 분명 큰 도약이지만
실제 인간의 뇌가 할 수 있는 일들에 비하면 이는 매우 간단한 일입니다.
그렇다면 뇌의 기능 중 인공신경망이 지니지 못한 결정적인 능력은 무엇일까요.

사람의 뇌는 인공신경망과 비교하면 그 능력이
너무나도 무궁무진하여 콕 집어 말할 수는 없습니다.
하지만 개인적으로는, 연이어 일어나는 사건들의 순서와 상호작용을 파악한 후 전체적인 상황에 대한
정확한 이해를 하는 능력이라고 생각합니다.
소설을 읽는 것을 상상해 보세요.
우리는 소설의 첫 페이지부터 마지막 페이지까지 모든 문장을 차례대로 읽어나갑니다.
그러므로써 소설 속 여러 사건들의 연대기와 상호작용을 파악하고, 결국엔
전체적인 줄거리를 이해합니다.
이처럼 연달아 발생한 사건(데이터)들의 흐름을 이해하고 이를 기반으로
학습하는 새로운 형태의 신경망이 바로 이번 장의 토픽인 RNN(Recurrent Neural Network)입니다.

RNN 은 지금까지 우리가 배워온 신경망과는 약간 다른 형태의 데이터를 입력받습니다.
앞 장의 Fashion MNIST 데이터는
고정된 크기의 특성값을 지닌 하나의 벡터 형태를 띄고 있었습니다.
이에 비해 RNN에 입력되는 '순차적 데이터(Sequential Data)'는 일반적으로
여러개의 벡터들이 특정한 순서대로 나열된 배열(Sequence) 형태를 띄고 있습니다.
RNN은 배열 속 벡터들의 상관관계와 순서정보를 학습하여
하나의 고정된 크기의 벡터로 압축시킵니다.
이해를 돕기 위해 아주 간단한 예를 들어 보겠습니다.

```
문장 1: ‘What a good lecture it was.’
문장 2: ‘It was a good lecture.’
```

만약 위 문장 속 모든 단어들이 5개의 특성값을 지닌 벡터로 나타내어 질 수 있다면 
문장 1에는 특성값이 30개가 있는 반면 문장 2에는 벡터가 25개가 있게 됩니다.
이러한 상황에서 문장 1 과 2 는 RNN 을 거치게 되고, 같은 차원의 벡터로 압축됩니다.

데이터의 연속성이 주는 정보를 학습 할 수 있다는 점에서 RNN이 매우
어렵고 새로운 개념이라는 생각이 들 수도 있습니다.
하지만 RNN은 1982년 존 홉필드(John Hopfield)에 의해 
처음으로 발명된 이후 지금까지 30년도 더 넘게 연구되어 왔습니다.
실제로 RNN을 학습시키는 방법은 1990 년 폴 J. 웨보스(Paul J. Werbos)
가 ‘시간에 따른 역전파 알고리즘(Backpropagation Through Time)’을 명확히 정의함으로써 완성되었고,
현재는 LSTM(Long Short Term Memory), GRU(Gated Recurrent Unit) 등
새로운 형태의 RNN이 발명되었습니다.
이러한 RNN들은 텍스트 감정 분석(Text Sentiment Analysis),
기계 번역(Machine Translation), 이미지 캡셔닝(Image Captioning)
등의 다양한 분야에 활발하게 적용되고 있습니다.
